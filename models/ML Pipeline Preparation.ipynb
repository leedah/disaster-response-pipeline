{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, fbeta_score, classification_report, recall_score, precision_score\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM InsertTableName\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "\n",
    "# categories are all columns after the 4th column\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenization function to process  text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Machine learning pipeline\n",
    "This machine learning pipeline takes in the `message` column as input, and outputs the classification results on the other 36 categories in the dataset using the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) classifier for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(DecisionTreeClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, Y_train)\n",
    "model = pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test  model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 92.94% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.82      0.84      0.83      3998\n",
      "               request       0.57      0.55      0.56       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.64      0.61      0.62      2164\n",
      "          medical_help       0.33      0.31      0.32       435\n",
      "      medical_products       0.39      0.33      0.35       279\n",
      "     search_and_rescue       0.23      0.21      0.22       136\n",
      "              security       0.07      0.06      0.07        96\n",
      "              military       0.38      0.37      0.38       158\n",
      "                 water       0.65      0.64      0.64       335\n",
      "                  food       0.75      0.73      0.74       584\n",
      "               shelter       0.63      0.61      0.62       468\n",
      "              clothing       0.47      0.51      0.49        70\n",
      "                 money       0.35      0.35      0.35       112\n",
      "        missing_people       0.25      0.16      0.19        63\n",
      "              refugees       0.35      0.31      0.33       170\n",
      "                 death       0.61      0.57      0.59       247\n",
      "             other_aid       0.28      0.26      0.27       692\n",
      "infrastructure_related       0.19      0.15      0.17       336\n",
      "             transport       0.24      0.21      0.22       235\n",
      "             buildings       0.44      0.39      0.41       269\n",
      "           electricity       0.43      0.33      0.37       115\n",
      "                 tools       0.06      0.03      0.04        35\n",
      "             hospitals       0.10      0.10      0.10        52\n",
      "                 shops       0.05      0.04      0.04        25\n",
      "           aid_centers       0.05      0.03      0.04        64\n",
      "  other_infrastructure       0.16      0.12      0.14       225\n",
      "       weather_related       0.73      0.71      0.72      1472\n",
      "                floods       0.61      0.56      0.59       431\n",
      "                 storm       0.65      0.66      0.65       479\n",
      "                  fire       0.26      0.25      0.25        53\n",
      "            earthquake       0.79      0.77      0.78       515\n",
      "                  cold       0.44      0.43      0.43       104\n",
      "         other_weather       0.29      0.25      0.27       267\n",
      "         direct_report       0.53      0.50      0.52      1010\n",
      "\n",
      "           avg / total       0.60      0.59      0.60     16609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# overall accuracy\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# If some labels are not predicted at least once, Y_pred will have different \n",
    "# columns than Y_test, which will cause an error in the classification_report()\n",
    "# So make sure Y_pred has the same labels as Y_test.\n",
    "\n",
    "Y_pred = pd.DataFrame(Y_pred);\n",
    "Y_pred.columns = Y_test.columns;\n",
    "Y_pred.index = Y_test.index;\n",
    "\n",
    "print(classification_report(Y_test, Y_pred, target_names=Y_pred.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['related' 'request' 'aid_related' 'shelter' 'infrastructure_related'\n",
      " 'buildings' 'other_infrastructure' 'direct_report']\n"
     ]
    }
   ],
   "source": [
    "# test msg\n",
    "\n",
    "msg = ['I need help, my house is destroyed']\n",
    "test_output = pipeline.predict(msg)\n",
    "print(Y_train.columns.values[(test_output.flatten()==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])\n",
    "\n",
    "\n",
    "# check pipeline parameters\n",
    "# pipeline.get_params()\n",
    "\n",
    "parameters = {\n",
    "        'clf__estimator__n_estimators': [10, 20],\n",
    "        'clf__estimator__learning_rate': [0.5, 1]\n",
    "\n",
    "    } \n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, n_jobs = -1, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, Y_train)\n",
    "model = cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.55% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.81      0.95      0.88      3998\n",
      "               request       0.78      0.48      0.60       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.74      0.55      0.63      2164\n",
      "          medical_help       0.61      0.25      0.35       435\n",
      "      medical_products       0.70      0.27      0.39       279\n",
      "     search_and_rescue       0.69      0.15      0.24       136\n",
      "              security       0.14      0.02      0.04        96\n",
      "              military       0.53      0.22      0.31       158\n",
      "                 water       0.74      0.58      0.65       335\n",
      "                  food       0.82      0.66      0.73       584\n",
      "               shelter       0.77      0.46      0.57       468\n",
      "              clothing       0.76      0.46      0.57        70\n",
      "                 money       0.54      0.29      0.37       112\n",
      "        missing_people       0.81      0.27      0.40        63\n",
      "              refugees       0.57      0.23      0.33       170\n",
      "                 death       0.84      0.39      0.54       247\n",
      "             other_aid       0.46      0.10      0.16       692\n",
      "infrastructure_related       0.46      0.10      0.16       336\n",
      "             transport       0.72      0.14      0.24       235\n",
      "             buildings       0.74      0.34      0.47       269\n",
      "           electricity       0.72      0.18      0.29       115\n",
      "                 tools       0.33      0.06      0.10        35\n",
      "             hospitals       0.40      0.08      0.13        52\n",
      "                 shops       0.00      0.00      0.00        25\n",
      "           aid_centers       0.29      0.06      0.10        64\n",
      "  other_infrastructure       0.37      0.08      0.13       225\n",
      "       weather_related       0.87      0.61      0.72      1472\n",
      "                floods       0.91      0.52      0.66       431\n",
      "                 storm       0.78      0.43      0.56       479\n",
      "                  fire       0.59      0.19      0.29        53\n",
      "            earthquake       0.89      0.79      0.84       515\n",
      "                  cold       0.67      0.32      0.43       104\n",
      "         other_weather       0.49      0.12      0.20       267\n",
      "         direct_report       0.71      0.45      0.55      1010\n",
      "\n",
      "           avg / total       0.74      0.56      0.61     16609\n",
      "\n",
      "\n",
      "Best Parameters: {'clf__estimator__learning_rate': 1, 'clf__estimator__n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# overall accuracy\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# If some labels are not predicted at least once, Y_pred will have different \n",
    "# columns than Y_test, which will cause an error in the classification_report()\n",
    "# So make sure Y_pred has the same labels as Y_test.\n",
    "\n",
    "Y_pred = pd.DataFrame(Y_pred);\n",
    "Y_pred.columns = Y_test.columns;\n",
    "Y_pred.index = Y_test.index;\n",
    "\n",
    "print(classification_report(Y_test, Y_pred, target_names=Y_pred.columns))\n",
    "\n",
    "print(\"\\nBest Parameters:\", model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improve  model further:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(LinearSVC()))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "        'clf__estimator__loss': ('hinge', 'squared_hinge'),\n",
    "        'clf__estimator__C': (0.5, 1.0)\n",
    "    } \n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, n_jobs = -1, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pipeline\n",
    "cv.fit(X_train, Y_train)\n",
    "model = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.13% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.86      0.93      0.90      3998\n",
      "               request       0.80      0.59      0.68       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.76      0.70      0.73      2164\n",
      "          medical_help       0.65      0.23      0.34       435\n",
      "      medical_products       0.72      0.25      0.37       279\n",
      "     search_and_rescue       0.67      0.16      0.26       136\n",
      "              security       0.00      0.00      0.00        96\n",
      "              military       0.58      0.21      0.31       158\n",
      "                 water       0.76      0.65      0.70       335\n",
      "                  food       0.82      0.77      0.79       584\n",
      "               shelter       0.81      0.56      0.66       468\n",
      "              clothing       0.70      0.47      0.56        70\n",
      "                 money       0.68      0.17      0.27       112\n",
      "        missing_people       1.00      0.16      0.27        63\n",
      "              refugees       0.68      0.20      0.31       170\n",
      "                 death       0.78      0.47      0.59       247\n",
      "             other_aid       0.67      0.09      0.15       692\n",
      "infrastructure_related       1.00      0.00      0.01       336\n",
      "             transport       0.75      0.14      0.24       235\n",
      "             buildings       0.79      0.30      0.43       269\n",
      "           electricity       0.81      0.22      0.34       115\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.00      0.00      0.00        52\n",
      "                 shops       0.00      0.00      0.00        25\n",
      "           aid_centers       0.00      0.00      0.00        64\n",
      "  other_infrastructure       0.00      0.00      0.00       225\n",
      "       weather_related       0.85      0.73      0.79      1472\n",
      "                floods       0.93      0.51      0.66       431\n",
      "                 storm       0.76      0.63      0.69       479\n",
      "                  fire       0.75      0.28      0.41        53\n",
      "            earthquake       0.90      0.79      0.84       515\n",
      "                  cold       0.72      0.27      0.39       104\n",
      "         other_weather       0.73      0.11      0.19       267\n",
      "         direct_report       0.74      0.49      0.59      1010\n",
      "\n",
      "           avg / total       0.78      0.60      0.64     16609\n",
      "\n",
      "\n",
      "Best Parameters: {'clf__estimator__C': 1.0, 'clf__estimator__loss': 'hinge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# overall accuracy\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "\n",
    "# If some labels are not predicted at least once, Y_pred will have different \n",
    "# columns than Y_test, which will cause an error in the classification_report()\n",
    "# So make sure Y_pred has the same labels as Y_test.\n",
    "\n",
    "Y_pred = pd.DataFrame(Y_pred);\n",
    "Y_pred.columns = Y_test.columns;\n",
    "Y_pred.index = Y_test.index;\n",
    "\n",
    "print(classification_report(Y_test, Y_pred, target_names=Y_pred.columns))\n",
    "\n",
    "print(\"\\nBest Parameters:\", model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.dumps('classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
