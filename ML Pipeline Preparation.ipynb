{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, fbeta_score, classification_report\n",
    "\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM InsertTableName\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "      <td>26215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15224.871333</td>\n",
       "      <td>0.766470</td>\n",
       "      <td>0.170666</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.414267</td>\n",
       "      <td>0.079496</td>\n",
       "      <td>0.050086</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.032806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>0.278352</td>\n",
       "      <td>0.082205</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.093649</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.052489</td>\n",
       "      <td>0.193591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8827.053788</td>\n",
       "      <td>0.423085</td>\n",
       "      <td>0.376224</td>\n",
       "      <td>0.066941</td>\n",
       "      <td>0.492604</td>\n",
       "      <td>0.270517</td>\n",
       "      <td>0.218126</td>\n",
       "      <td>0.163878</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.178131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107929</td>\n",
       "      <td>0.204890</td>\n",
       "      <td>0.448196</td>\n",
       "      <td>0.274682</td>\n",
       "      <td>0.290705</td>\n",
       "      <td>0.103160</td>\n",
       "      <td>0.291345</td>\n",
       "      <td>0.140746</td>\n",
       "      <td>0.223015</td>\n",
       "      <td>0.395120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7446.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15663.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22924.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30265.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       related       request         offer   aid_related  \\\n",
       "count  26215.000000  26215.000000  26215.000000  26215.000000  26215.000000   \n",
       "mean   15224.871333      0.766470      0.170666      0.004501      0.414267   \n",
       "std     8827.053788      0.423085      0.376224      0.066941      0.492604   \n",
       "min        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     7446.500000      1.000000      0.000000      0.000000      0.000000   \n",
       "50%    15663.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%    22924.500000      1.000000      0.000000      0.000000      1.000000   \n",
       "max    30265.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       medical_help  medical_products  search_and_rescue      security  \\\n",
       "count  26215.000000      26215.000000       26215.000000  26215.000000   \n",
       "mean       0.079496          0.050086           0.027618      0.017967   \n",
       "std        0.270517          0.218126           0.163878      0.132833   \n",
       "min        0.000000          0.000000           0.000000      0.000000   \n",
       "25%        0.000000          0.000000           0.000000      0.000000   \n",
       "50%        0.000000          0.000000           0.000000      0.000000   \n",
       "75%        0.000000          0.000000           0.000000      0.000000   \n",
       "max        1.000000          1.000000           1.000000      1.000000   \n",
       "\n",
       "           military      ...         aid_centers  other_infrastructure  \\\n",
       "count  26215.000000      ...        26215.000000          26215.000000   \n",
       "mean       0.032806      ...            0.011787              0.043906   \n",
       "std        0.178131      ...            0.107929              0.204890   \n",
       "min        0.000000      ...            0.000000              0.000000   \n",
       "25%        0.000000      ...            0.000000              0.000000   \n",
       "50%        0.000000      ...            0.000000              0.000000   \n",
       "75%        0.000000      ...            0.000000              0.000000   \n",
       "max        1.000000      ...            1.000000              1.000000   \n",
       "\n",
       "       weather_related        floods         storm          fire  \\\n",
       "count     26215.000000  26215.000000  26215.000000  26215.000000   \n",
       "mean          0.278352      0.082205      0.093191      0.010757   \n",
       "std           0.448196      0.274682      0.290705      0.103160   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      0.000000   \n",
       "50%           0.000000      0.000000      0.000000      0.000000   \n",
       "75%           1.000000      0.000000      0.000000      0.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         earthquake          cold  other_weather  direct_report  \n",
       "count  26215.000000  26215.000000   26215.000000   26215.000000  \n",
       "mean       0.093649      0.020217       0.052489       0.193591  \n",
       "std        0.291345      0.140746       0.223015       0.395120  \n",
       "min        0.000000      0.000000       0.000000       0.000000  \n",
       "25%        0.000000      0.000000       0.000000       0.000000  \n",
       "50%        0.000000      0.000000       0.000000       0.000000  \n",
       "75%        0.000000      0.000000       0.000000       0.000000  \n",
       "max        1.000000      1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "\n",
    "# categories are all columns after the 4th column\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenization function to process  text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Machine learning pipeline\n",
    "This machine learning pipeline takes in the `message` column as input, and outputs the classification results on the other 36 categories in the dataset using the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) classifier for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...mator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train pipeline\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test  model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.71% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88      3998\n",
      "               request       0.79      0.54      0.64       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.76      0.59      0.67      2164\n",
      "          medical_help       0.63      0.26      0.37       435\n",
      "      medical_products       0.60      0.32      0.42       279\n",
      "     search_and_rescue       0.60      0.18      0.27       136\n",
      "              security       0.13      0.02      0.04        96\n",
      "              military       0.57      0.25      0.35       158\n",
      "                 water       0.74      0.62      0.68       335\n",
      "                  food       0.85      0.70      0.77       584\n",
      "               shelter       0.77      0.56      0.65       468\n",
      "              clothing       0.82      0.44      0.57        70\n",
      "                 money       0.51      0.27      0.35       112\n",
      "        missing_people       0.50      0.14      0.22        63\n",
      "              refugees       0.55      0.24      0.33       170\n",
      "                 death       0.78      0.47      0.58       247\n",
      "             other_aid       0.46      0.14      0.21       692\n",
      "infrastructure_related       0.44      0.09      0.15       336\n",
      "             transport       0.67      0.16      0.26       235\n",
      "             buildings       0.71      0.36      0.48       269\n",
      "           electricity       0.68      0.22      0.33       115\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.36      0.10      0.15        52\n",
      "                 shops       0.00      0.00      0.00        25\n",
      "           aid_centers       0.20      0.06      0.10        64\n",
      "  other_infrastructure       0.29      0.07      0.11       225\n",
      "       weather_related       0.86      0.65      0.74      1472\n",
      "                floods       0.91      0.55      0.69       431\n",
      "                 storm       0.76      0.48      0.59       479\n",
      "                  fire       0.50      0.17      0.25        53\n",
      "            earthquake       0.89      0.78      0.83       515\n",
      "                  cold       0.71      0.31      0.43       104\n",
      "         other_weather       0.51      0.17      0.26       267\n",
      "         direct_report       0.71      0.46      0.56      1010\n",
      "\n",
      "           avg / total       0.74      0.58      0.63     16609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "# classification report on test data\n",
    "\n",
    "print(classification_report(Y_test.values, Y_pred, target_names=Y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['related' 'request' 'aid_related' 'shelter' 'buildings' 'fire'\n",
      " 'direct_report']\n"
     ]
    }
   ],
   "source": [
    "# test msg\n",
    "\n",
    "msg = ['Hello I see fire in the street and many houses are destroyed, homeless people everywhere']\n",
    "test_output = pipeline.predict(msg)\n",
    "print(Y_train.columns.values[(test_output.flatten()==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pipeline parameters\n",
    "# pipeline.get_params()\n",
    "\n",
    "parameters = {\n",
    "        'clf__estimator__n_estimators': [10, 20],\n",
    "        'clf__estimator__learning_rate': [0.1, 0.5, 1]\n",
    "\n",
    "    } \n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, n_jobs = -1, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...mator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "           n_jobs=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__estimator__n_estimators': [10, 20], 'clf__estimator__learning_rate': [0.1, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!\n",
    "\n",
    "Try:\n",
    "Inherently multiclass: Naive Bayes, LDA and QDA, Decision Trees, Random Forests, Nearest Neighbors, setting multi_class='multinomial' in sklearn.linear_model.LogisticRegression.\n",
    "Support multilabel: Decision Trees, Random Forests, Nearest Neighbors.\n",
    "One-Vs-One: sklearn.svm.SVC.\n",
    "One-Vs-All: all linear models except sklearn.svm.SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 94.55% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.81      0.95      0.88      3998\n",
      "               request       0.78      0.48      0.60       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.74      0.55      0.63      2164\n",
      "          medical_help       0.61      0.25      0.35       435\n",
      "      medical_products       0.70      0.27      0.39       279\n",
      "     search_and_rescue       0.69      0.15      0.24       136\n",
      "              security       0.14      0.02      0.04        96\n",
      "              military       0.53      0.22      0.31       158\n",
      "                 water       0.74      0.58      0.65       335\n",
      "                  food       0.82      0.66      0.73       584\n",
      "               shelter       0.77      0.46      0.57       468\n",
      "              clothing       0.76      0.46      0.57        70\n",
      "                 money       0.54      0.29      0.37       112\n",
      "        missing_people       0.81      0.27      0.40        63\n",
      "              refugees       0.57      0.23      0.33       170\n",
      "                 death       0.84      0.39      0.54       247\n",
      "             other_aid       0.46      0.10      0.16       692\n",
      "infrastructure_related       0.46      0.10      0.16       336\n",
      "             transport       0.72      0.14      0.24       235\n",
      "             buildings       0.74      0.34      0.47       269\n",
      "           electricity       0.72      0.18      0.29       115\n",
      "                 tools       0.33      0.06      0.10        35\n",
      "             hospitals       0.40      0.08      0.13        52\n",
      "                 shops       0.00      0.00      0.00        25\n",
      "           aid_centers       0.29      0.06      0.10        64\n",
      "  other_infrastructure       0.37      0.08      0.13       225\n",
      "       weather_related       0.87      0.61      0.72      1472\n",
      "                floods       0.91      0.52      0.66       431\n",
      "                 storm       0.78      0.43      0.56       479\n",
      "                  fire       0.59      0.19      0.29        53\n",
      "            earthquake       0.89      0.79      0.84       515\n",
      "                  cold       0.67      0.32      0.43       104\n",
      "         other_weather       0.49      0.12      0.20       267\n",
      "         direct_report       0.71      0.45      0.55      1010\n",
      "\n",
      "           avg / total       0.74      0.56      0.61     16609\n",
      "\n",
      "\n",
      "Best Parameters: {'clf__estimator__learning_rate': 1, 'clf__estimator__n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "# classification report on test data\n",
    "print(classification_report(Y_test.values, Y_pred, target_names=Y.columns.values))\n",
    "\n",
    "print(\"\\nBest Parameters:\", cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom transformer\n",
    "\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "\n",
    "        ('text_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "\n",
    "        ('starting_verb', StartingVerbExtractor())\n",
    "    ])),\n",
    "\n",
    "    ('clf', MultiOutputClassifier(LinearSVC()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'clf__estimator__loss': ('hinge', 'squared_hinge'),\n",
    "        'clf__estimator__C': (0.01, 0.5, 1.0)\n",
    "    } \n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=pipeline, n_jobs = -1, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pipeline\n",
    "cv.fit(X_train, Y_train)\n",
    "Y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.12% \n",
      "\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.86      0.93      0.90      3998\n",
      "               request       0.80      0.59      0.68       891\n",
      "                 offer       0.00      0.00      0.00        24\n",
      "           aid_related       0.76      0.70      0.73      2164\n",
      "          medical_help       0.65      0.23      0.34       435\n",
      "      medical_products       0.72      0.25      0.37       279\n",
      "     search_and_rescue       0.67      0.16      0.26       136\n",
      "              security       0.00      0.00      0.00        96\n",
      "              military       0.58      0.21      0.31       158\n",
      "                 water       0.76      0.65      0.70       335\n",
      "                  food       0.83      0.77      0.80       584\n",
      "               shelter       0.81      0.56      0.66       468\n",
      "              clothing       0.70      0.47      0.56        70\n",
      "                 money       0.68      0.17      0.27       112\n",
      "        missing_people       1.00      0.16      0.27        63\n",
      "              refugees       0.68      0.20      0.31       170\n",
      "                 death       0.78      0.47      0.59       247\n",
      "             other_aid       0.66      0.08      0.15       692\n",
      "infrastructure_related       1.00      0.00      0.01       336\n",
      "             transport       0.75      0.14      0.24       235\n",
      "             buildings       0.80      0.30      0.43       269\n",
      "           electricity       0.81      0.22      0.34       115\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.00      0.00      0.00        52\n",
      "                 shops       0.00      0.00      0.00        25\n",
      "           aid_centers       0.00      0.00      0.00        64\n",
      "  other_infrastructure       0.00      0.00      0.00       225\n",
      "       weather_related       0.85      0.73      0.79      1472\n",
      "                floods       0.93      0.51      0.66       431\n",
      "                 storm       0.76      0.63      0.69       479\n",
      "                  fire       0.75      0.28      0.41        53\n",
      "            earthquake       0.90      0.79      0.85       515\n",
      "                  cold       0.72      0.27      0.39       104\n",
      "         other_weather       0.73      0.11      0.19       267\n",
      "         direct_report       0.73      0.48      0.58      1010\n",
      "\n",
      "           avg / total       0.78      0.60      0.64     16609\n",
      "\n",
      "\n",
      "Best Parameters: {'clf__estimator__C': 1.0, 'clf__estimator__loss': 'hinge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy\n",
    "accuracy = (Y_pred == Y_test).mean().mean()\n",
    "print('Accuracy {0:.2f}% \\n'.format(accuracy*100))\n",
    "\n",
    "# classification report on test data\n",
    "print(classification_report(Y_test.values, Y_pred, target_names=Y.columns.values))\n",
    "\n",
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.dumps('classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
